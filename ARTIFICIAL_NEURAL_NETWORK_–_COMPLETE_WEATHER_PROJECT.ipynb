{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhRCRCLIlhjL6T8jSUqwZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Devisri01/Python-colab/blob/main/ARTIFICIAL_NEURAL_NETWORK_%E2%80%93_COMPLETE_WEATHER_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR49_eGfCDfo",
        "outputId": "6495f1aa-0278-4532-b48c-4025a2f95266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä WEATHER DATASET\n",
            "   Temperature  Humidity  Windy  Rain\n",
            "0           30        70      0     1\n",
            "1           25        80      1     1\n",
            "2           28        65      0     0\n",
            "3           35        90      1     1\n",
            "4           20        85      0     0\n",
            "5           18        75      1     0\n",
            "6           22        60      0     0\n",
            "7           33        95      1     1\n",
            "8           27        78      0     1\n",
            "9           24        68      1     0\n",
            "\n",
            "üî¥ PERCEPTRON MODEL\n",
            "Perceptron Predictions: [1 1 1 1 1 1 1 1 1 1]\n",
            "\n",
            "‚ö†Ô∏è Limitation:\n",
            "‚Ä¢ Perceptron learns only LINEAR patterns\n",
            "‚Ä¢ Fails on complex / non-linear data\n",
            "\n",
            "\n",
            "üü¢ MULTILAYER PERCEPTRON (MLP)\n",
            "MLP Predictions: [1 1 0 1 0 0 0 1 1 0]\n",
            "\n",
            "‚úÖ MLP Advantages:\n",
            "‚Ä¢ Multiple neurons\n",
            "‚Ä¢ Activation functions\n",
            "‚Ä¢ Learns NON-LINEAR patterns\n",
            "\n",
            "\n",
            "‚û°Ô∏è FORWARD PROPAGATION OUTPUT (Probabilities)\n",
            "[[0.162 0.838]\n",
            " [0.083 0.917]\n",
            " [0.86  0.14 ]\n",
            " [0.    1.   ]\n",
            " [0.618 0.382]\n",
            " [0.969 0.031]\n",
            " [0.994 0.006]\n",
            " [0.    1.   ]\n",
            " [0.09  0.91 ]\n",
            " [0.962 0.038]]\n",
            "\n",
            "Each row:\n",
            "[ Probability(No Rain), Probability(Rain) ]\n",
            "\n",
            "\n",
            "‚ö° ACTIVATION FUNCTIONS\n",
            "Input:    [-3 -1  0  1  3]\n",
            "ReLU:     [0 0 0 1 3]\n",
            "Sigmoid:  [0.047 0.269 0.5   0.731 0.953]\n",
            "Tanh:     [-0.995 -0.762  0.     0.762  0.995]\n",
            "\n",
            "Activation Purpose:\n",
            "‚Ä¢ ReLU ‚Üí hidden layers\n",
            "‚Ä¢ Sigmoid ‚Üí binary output\n",
            "‚Ä¢ Tanh ‚Üí centered data\n",
            "\n",
            "\n",
            "üìâ LOSS FUNCTIONS\n",
            "Mean Squared Error (MSE): 0.08\n",
            "\n",
            "‚õ∞Ô∏è GRADIENT DESCENT DEMO\n",
            "Step 1 | Weight: 1.900 | Loss: 10.500\n",
            "Step 2 | Weight: 1.993 | Loss: 0.047\n",
            "Step 3 | Weight: 2.000 | Loss: 0.000\n",
            "Step 4 | Weight: 2.000 | Loss: 0.000\n",
            "\n",
            "Gradient Descent:\n",
            "‚Ä¢ Computes error (loss)\n",
            "‚Ä¢ Finds direction to reduce error\n",
            "‚Ä¢ Updates weights step by step\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ARTIFICIAL NEURAL NETWORK ‚Äì COMPLETE WEATHER PROJECT\n",
        "# ============================================================\n",
        "# Topics Covered:\n",
        "# 1. Weather Dataset\n",
        "# 2. Perceptron & Its Limitation\n",
        "# 3. Multilayer Perceptron (MLP)\n",
        "# 4. Forward Propagation\n",
        "# 5. Activation Functions\n",
        "# 6. Loss Functions\n",
        "# 7. Gradient Descent Intuition\n",
        "# ============================================================\n",
        "\n",
        "# ======================\n",
        "# IMPORT LIBRARIES\n",
        "# ======================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ CREATE WEATHER DATASET\n",
        "# ============================================================\n",
        "# Features:\n",
        "# - Temperature (¬∞C)\n",
        "# - Humidity (%)\n",
        "# - Windy (0 = No, 1 = Yes)\n",
        "# Target:\n",
        "# - Rain (1 = Yes, 0 = No)\n",
        "\n",
        "data = {\n",
        "    \"Temperature\": [30, 25, 28, 35, 20, 18, 22, 33, 27, 24],\n",
        "    \"Humidity\": [70, 80, 65, 90, 85, 75, 60, 95, 78, 68],\n",
        "    \"Windy\": [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    \"Rain\": [1, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"\\nüìä WEATHER DATASET\")\n",
        "print(df)\n",
        "\n",
        "# Split features and target\n",
        "X = df[['Temperature', 'Humidity', 'Windy']]\n",
        "y = df['Rain']\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ PERCEPTRON (SINGLE NEURON)\n",
        "# ============================================================\n",
        "print(\"\\nüî¥ PERCEPTRON MODEL\")\n",
        "\n",
        "perceptron = Perceptron(max_iter=1000, random_state=42)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "perceptron_predictions = perceptron.predict(X)\n",
        "print(\"Perceptron Predictions:\", perceptron_predictions)\n",
        "\n",
        "print(\"\"\"\n",
        "‚ö†Ô∏è Limitation:\n",
        "‚Ä¢ Perceptron learns only LINEAR patterns\n",
        "‚Ä¢ Fails on complex / non-linear data\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ MULTILAYER PERCEPTRON (MLP)\n",
        "# ============================================================\n",
        "print(\"\\nüü¢ MULTILAYER PERCEPTRON (MLP)\")\n",
        "\n",
        "# Feature scaling (important for NN)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(3,),\n",
        "    activation='relu',\n",
        "    max_iter=2000,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp.fit(X_scaled, y)\n",
        "mlp_predictions = mlp.predict(X_scaled)\n",
        "\n",
        "print(\"MLP Predictions:\", mlp_predictions)\n",
        "\n",
        "print(\"\"\"\n",
        "‚úÖ MLP Advantages:\n",
        "‚Ä¢ Multiple neurons\n",
        "‚Ä¢ Activation functions\n",
        "‚Ä¢ Learns NON-LINEAR patterns\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ FORWARD PROPAGATION (Probabilities)\n",
        "# ============================================================\n",
        "print(\"\\n‚û°Ô∏è FORWARD PROPAGATION OUTPUT (Probabilities)\")\n",
        "\n",
        "probabilities = mlp.predict_proba(X_scaled)\n",
        "print(np.round(probabilities, 3))\n",
        "\n",
        "print(\"\"\"\n",
        "Each row:\n",
        "[ Probability(No Rain), Probability(Rain) ]\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ ACTIVATION FUNCTIONS\n",
        "# ============================================================\n",
        "print(\"\\n‚ö° ACTIVATION FUNCTIONS\")\n",
        "\n",
        "x = np.array([-3, -1, 0, 1, 3])\n",
        "\n",
        "relu = np.maximum(0, x)\n",
        "sigmoid = 1 / (1 + np.exp(-x))\n",
        "tanh = np.tanh(x)\n",
        "\n",
        "print(\"Input:   \", x)\n",
        "print(\"ReLU:    \", relu)\n",
        "print(\"Sigmoid: \", np.round(sigmoid, 3))\n",
        "print(\"Tanh:    \", np.round(tanh, 3))\n",
        "\n",
        "print(\"\"\"\n",
        "Activation Purpose:\n",
        "‚Ä¢ ReLU ‚Üí hidden layers\n",
        "‚Ä¢ Sigmoid ‚Üí binary output\n",
        "‚Ä¢ Tanh ‚Üí centered data\n",
        "\"\"\")\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ LOSS FUNCTIONS\n",
        "# ============================================================\n",
        "print(\"\\nüìâ LOSS FUNCTIONS\")\n",
        "\n",
        "# Mean Squared Error (example)\n",
        "y_true = np.array([1, 0, 1])\n",
        "y_pred = np.array([0.8, 0.2, 0.6])\n",
        "\n",
        "mse = np.mean((y_true - y_pred) ** 2)\n",
        "print(\"Mean Squared Error (MSE):\", round(mse, 3))\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ GRADIENT DESCENT INTUITION\n",
        "# ============================================================\n",
        "print(\"\\n‚õ∞Ô∏è GRADIENT DESCENT DEMO\")\n",
        "\n",
        "# Simple linear example: y = 2x\n",
        "X_gd = np.array([1, 2, 3])\n",
        "y_gd = np.array([2, 4, 6])\n",
        "\n",
        "w = 0.5        # Initial weight\n",
        "lr = 0.1       # Learning rate\n",
        "\n",
        "for step in range(4):\n",
        "    y_pred_gd = w * X_gd\n",
        "    loss = np.mean((y_gd - y_pred_gd) ** 2)\n",
        "    gradient = -2 * np.mean(X_gd * (y_gd - y_pred_gd))\n",
        "    w = w - lr * gradient\n",
        "\n",
        "    print(f\"Step {step+1} | Weight: {w:.3f} | Loss: {loss:.3f}\")\n",
        "\n",
        "print(\"\"\"\n",
        "Gradient Descent:\n",
        "‚Ä¢ Computes error (loss)\n",
        "‚Ä¢ Finds direction to reduce error\n",
        "‚Ä¢ Updates weights step by step\n",
        "\"\"\")\n"
      ]
    }
  ]
}