{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOqMvM+P95os/+pkMAAOXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Devisri01/Python-colab/blob/main/Python_gen_ai_day_6%2C7_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQDa5c0T4GRX",
        "outputId": "72cf59ee-883f-4aa1-ccbf-c6c0df7bd31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation R² scores: [0.89006932 0.89772997 0.90819285 0.87589803 0.88310694]\n",
            "Average CV Score: 0.8909994215752061\n",
            "Best Alpha: {'alpha': 1}\n",
            "Best CV Score: 0.8909994215752061\n",
            "R²: 0.8925838993553217\n",
            "Adjusted R²: 0.8922603568835004\n",
            "AIC: 19848.681846282172\n",
            "BIC: 19868.3128673981\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import r2_score\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/employee_salary.csv\")\n",
        "X = df[[\"Experience\", \"EducationLevel\", \"Age\"]]\n",
        "y = df[\"Salary\"]\n",
        "\n",
        "# Cross-Validation with Ridge\n",
        "ridge = Ridge(alpha=1.0)\n",
        "scores = cross_val_score(\n",
        "    ridge,\n",
        "    X,\n",
        "    y,\n",
        "    cv=5,\n",
        "    scoring=\"r2\"\n",
        ")\n",
        "print(\"Cross-Validation R² scores:\", scores)\n",
        "print(\"Average CV Score:\", np.mean(scores))\n",
        "\n",
        "# Grid Search for best alpha\n",
        "params = {\n",
        "    \"alpha\": [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "grid = GridSearchCV(\n",
        "    Ridge(),\n",
        "    params,\n",
        "    cv=5,\n",
        "    scoring=\"r2\"\n",
        ")\n",
        "grid.fit(X, y)\n",
        "print(\"Best Alpha:\", grid.best_params_)\n",
        "print(\"Best CV Score:\", grid.best_score_)\n",
        "\n",
        "# Adjusted R² (manual)\n",
        "best_ridge = Ridge(alpha=grid.best_params_[\"alpha\"])\n",
        "best_ridge.fit(X, y)\n",
        "y_pred = best_ridge.predict(X)\n",
        "r2 = r2_score(y, y_pred)\n",
        "n, k = X.shape\n",
        "adj_r2 = 1 - (1 - r2) * (n - 1) / (n - k - 1)\n",
        "print(\"R²:\", r2)\n",
        "print(\"Adjusted R²:\", adj_r2)\n",
        "\n",
        "# AIC & BIC using statsmodels\n",
        "X_const = sm.add_constant(X)   # add intercept\n",
        "ols_model = sm.OLS(y, X_const).fit()\n",
        "print(\"AIC:\", ols_model.aic)\n",
        "print(\"BIC:\", ols_model.bic)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Diagnosis - Accuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Actual results\n",
        "actual = [\"Pass\", \"Fail\", \"Pass\", \"Pass\", \"Fail\"]\n",
        "\n",
        "# Model predictions\n",
        "predicted = [\"Pass\", \"Fail\", \"Fail\", \"Pass\", \"Pass\"]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(actual, predicted)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONr-QPLn7TGM",
        "outputId": "394c3567-7ac0-47ec-fe3b-01a67606bd9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Example\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create example dataset\n",
        "data = {\n",
        "    \"Age\": [22, 25, 47, 52, 46],\n",
        "    \"Salary\": [20000, 30000, 50000, 60000, 80000],\n",
        "    \"Buy\": [0, 0, 1, 1, 1]   # 0 = No, 1 = Yes\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split features and target\n",
        "X = df[[\"Age\", \"Salary\"]]   # Features\n",
        "y = df[\"Buy\"]               # Target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train Logistic Regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "probs = model.predict_proba(X_test)\n",
        "print(\"Probabilities:\\n\", probs)\n",
        "\n",
        "# Predict class labels (0/1)\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Predictions:\\n\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNJRksQNQ8G5",
        "outputId": "aab686b3-e58d-47fa-e2e7-1ff9b227e156"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities:\n",
            " [[0.99669013 0.00330987]\n",
            " [0.         1.        ]]\n",
            "Predictions:\n",
            " [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression - Student Pass Prediction\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    \"StudyHours\": [2, 4, 6, 8, 1, 5, 7, 3],\n",
        "    \"Attendance\": [60, 65, 75, 90, 50, 70, 85, 55],\n",
        "    \"Pass\": [0, 0, 1, 1, 0, 1, 1, 0]   # 0 = Fail, 1 = Pass\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features & Target\n",
        "X = df[[\"StudyHours\", \"Attendance\"]]\n",
        "y = df[\"Pass\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.25,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)\n",
        "print(\"Predicted Classes:\", y_pred)\n",
        "print(\"Predicted Probabilities:\\n\", y_prob)\n",
        "\n",
        "# Model evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0EwdHpJR8mi",
        "outputId": "022af7d2-8b22-4447-bf8e-a88dac683e77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Classes: [0 1]\n",
            "Predicted Probabilities:\n",
            " [[0.76522135 0.23477865]\n",
            " [0.2353578  0.7646422 ]]\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression - Loan Approval Prediction (Fixed)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Create dataset\n",
        "data = {\n",
        "    \"Income\": [30000, 50000, 40000, 60000, 25000, 70000, 45000, 80000],\n",
        "    \"CreditScore\": [650, 720, 680, 750, 600, 780, 700, 820],\n",
        "    \"LoanAmount\": [100000, 150000, 120000, 200000, 90000, 250000, 140000, 300000],\n",
        "    \"Approved\": [0, 1, 0, 1, 0, 1, 1, 1]   # 0 = No, 1 = Yes\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features & Target\n",
        "X = df[[\"Income\", \"CreditScore\", \"LoanAmount\"]]\n",
        "y = df[\"Approved\"]\n",
        "\n",
        "# Stratified Train-test split (IMPORTANT FIX)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)\n",
        "print(\"Predicted Classes:\", y_pred)\n",
        "print(\"Predicted Probabilities:\\n\", y_prob)\n",
        "\n",
        "# Evaluation (FIXED confusion matrix)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpIirKUqSlso",
        "outputId": "3af7e74e-68d0-4ae6-9a3f-b8261a80c59b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Classes: [1 0]\n",
            "Predicted Probabilities:\n",
            " [[0.         1.        ]\n",
            " [0.98998051 0.01001949]]\n",
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[1 0]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix & Metrics\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.read_csv(\"/content/student_marks_dataset.csv\")\n",
        "print(df.head())\n",
        "\n",
        "# 2. Features & Target\n",
        "X = df[[\"StudyHours\", \"Attendance\"]]\n",
        "\n",
        "# Convert Pass = 1, Fail = 0\n",
        "y = (df[\"Result\"] == \"Pass\").astype(int)\n",
        "\n",
        "# 3. Train-test split (70% / 30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# 4. Train Logistic Regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Predict probabilities\n",
        "probs = model.predict_proba(X_test)\n",
        "print(\"Probabilities:\\n\", probs)\n",
        "\n",
        "# 6. Predict classes\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 7. Confusion Matrix & Metrics\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall:\", rec)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0pok1dqcZrEC",
        "outputId": "7a8303dc-4ef3-42ed-aac1-fb27f5d38eb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/student_marks_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2030447918.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 1. Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/student_marks_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/student_marks_dataset.csv'"
          ]
        }
      ]
    }
  ]
}