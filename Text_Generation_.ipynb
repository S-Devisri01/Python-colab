{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3sxCywDKBbJrDEGMOecNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/S-Devisri01/Python-colab/blob/main/Text_Generation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7C1D1UoLm7L-",
        "outputId": "1b12eec5-b0a3-4817-de67-1ed41f5df15c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total characters: 1115394\n",
            "first citizen:\n",
            "before we proceed any further, hear me speak.\n",
            "\n",
            "all:\n",
            "speak, speak.\n",
            "\n",
            "first citizen:\n",
            "you are all resolved rather to die than to famish?\n",
            "\n",
            "all:\n",
            "resolved. resolved.\n",
            "\n",
            "first citizen:\n",
            "first, you know caius marcius is chief enemy to the people.\n",
            "\n",
            "all:\n",
            "we know't, we know't.\n",
            "\n",
            "first citizen:\n",
            "let us kill him, and we'll have corn at our own price.\n",
            "is't a verdict?\n",
            "\n",
            "all:\n",
            "no more talking on't; let it be done: away, away!\n",
            "\n",
            "second citizen:\n",
            "one word, good citizens.\n",
            "\n",
            "first citizen:\n",
            "we are accounted poor\n",
            "Unique characters: 39\n",
            "Total sequences: 371785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">86,016</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m86,016\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)             â”‚         \u001b[38;5;34m5,031\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,047</span> (355.65 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,047\u001b[0m (355.65 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,047</span> (355.65 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91,047\u001b[0m (355.65 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 97ms/step - loss: 2.5741\n",
            "Epoch 2/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 98ms/step - loss: 1.9789\n",
            "Epoch 3/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 97ms/step - loss: 1.8349\n",
            "Epoch 4/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 98ms/step - loss: 1.7409\n",
            "Epoch 5/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 98ms/step - loss: 1.6704\n",
            "Epoch 6/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 98ms/step - loss: 1.6149\n",
            "Epoch 7/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 97ms/step - loss: 1.5691\n",
            "Epoch 8/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 97ms/step - loss: 1.5328\n",
            "Epoch 9/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 97ms/step - loss: 1.5052\n",
            "Epoch 10/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 98ms/step - loss: 1.4813\n",
            "Epoch 11/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 97ms/step - loss: 1.4593\n",
            "Epoch 12/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 96ms/step - loss: 1.4402\n",
            "Epoch 13/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 97ms/step - loss: 1.4262\n",
            "Epoch 14/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 96ms/step - loss: 1.4087\n",
            "Epoch 15/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 97ms/step - loss: 1.4021\n",
            "Epoch 16/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 96ms/step - loss: 1.3915\n",
            "Epoch 17/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 97ms/step - loss: 1.3727\n",
            "Epoch 18/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 99ms/step - loss: 1.3685\n",
            "Epoch 19/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 98ms/step - loss: 1.3550\n",
            "Epoch 20/20\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 98ms/step - loss: 1.3464\n",
            "Seed text:\n",
            "to-morrow?  well, all's one for that.\n",
            "wh\n",
            "\n",
            "Generated text:\n",
            "\n",
            "en i die entreas for thy brother, and them,\n",
            "and for it is once thou art virtues stand the other\n",
            "deach her life tage of one to the wars\n",
            "to god the book'd wold subjeck of the poopior:\n",
            "i come him about it enemies; in the roamspite of died-breath,\n",
            "and batter hath been antey's fait, and 't\n",
            "shall this breast in the vear and one good;\n",
            "and therefold the traitor bust and the denes\n",
            "and claim the brother of \n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q tensorflow numpy requests\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ================================\n",
        "# ğŸ“¥ Download Dataset (Tiny Shakespeare)\n",
        "# ================================\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "text = requests.get(url).text.lower()\n",
        "\n",
        "print(\"Total characters:\", len(text))\n",
        "print(text[:500])\n",
        "\n",
        "# ================================\n",
        "# ğŸ”¤ Create Character Mappings\n",
        "# ================================\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print(\"Unique characters:\", vocab_size)\n",
        "\n",
        "# ================================\n",
        "# ğŸ” Prepare Sequences\n",
        "# ================================\n",
        "SEQ_LEN = 40\n",
        "STEP = 3\n",
        "\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - SEQ_LEN, STEP):\n",
        "    sentences.append(text[i:i + SEQ_LEN])\n",
        "    next_chars.append(text[i + SEQ_LEN])\n",
        "\n",
        "print(\"Total sequences:\", len(sentences))\n",
        "\n",
        "# ================================\n",
        "# ğŸ“Š Vectorization\n",
        "# ================================\n",
        "X = np.zeros((len(sentences), SEQ_LEN, vocab_size), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), vocab_size), dtype=np.bool_)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, ch in enumerate(sentence):\n",
        "        X[i, t, char_to_idx[ch]] = 1\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1\n",
        "\n",
        "# ================================\n",
        "# ğŸ§  Build LSTM Model\n",
        "# ================================\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LEN, vocab_size)))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001)\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ================================\n",
        "# ğŸš€ Train Model\n",
        "# ================================\n",
        "model.fit(\n",
        "    X,\n",
        "    y,\n",
        "    batch_size=128,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# ğŸ”® Text Generation Function\n",
        "# ================================\n",
        "def generate_text(model, seed_text, length=400, temperature=1.0):\n",
        "    generated = \"\"\n",
        "    sentence = seed_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        x_pred = np.zeros((1, SEQ_LEN, vocab_size))\n",
        "        for t, ch in enumerate(sentence):\n",
        "            x_pred[0, t, char_to_idx[ch]] = 1\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        preds = np.log(preds + 1e-8) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        next_index = np.random.choice(len(preds), p=preds)\n",
        "        next_char = idx_to_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# ================================\n",
        "# ğŸ“Œ Generate Sample Text\n",
        "# ================================\n",
        "start_index = random.randint(0, len(text) - SEQ_LEN - 1)\n",
        "seed_text = text[start_index:start_index + SEQ_LEN]\n",
        "\n",
        "print(\"Seed text:\")\n",
        "print(seed_text)\n",
        "print(\"\\nGenerated text:\\n\")\n",
        "\n",
        "generated_text = generate_text(\n",
        "    model,\n",
        "    seed_text,\n",
        "    length=400,\n",
        "    temperature=0.8\n",
        ")\n",
        "\n",
        "print(generated_text)\n"
      ]
    }
  ]
}